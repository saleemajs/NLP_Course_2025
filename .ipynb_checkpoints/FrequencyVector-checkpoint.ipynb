{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b663229-632e-4675-85a6-921138a6fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef402057-8181-45ae-8c8f-ea52bfc19f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"NLP is fun and exciting\",\n",
    "    \"We are learning natural language processing\",\n",
    "    \"Machine learning powers modern NLP applications\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4246fc-ebfe-423e-8bbd-924c6a3ceda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary mapping:\n",
      "{'nlp': 11, 'is': 5, 'fun': 4, 'and': 0, 'exciting': 3, 'we': 14, 'are': 2, 'learning': 7, 'natural': 10, 'language': 6, 'processing': 13, 'machine': 8, 'powers': 12, 'modern': 9, 'applications': 1}\n"
     ]
    }
   ],
   "source": [
    "#(word â†’ index mapping)\n",
    "\n",
    "vocab = vectorizer.vocabulary_\n",
    "print(\"Vocabulary mapping:\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cccbe33-414a-40be-b8a5-983d60dc37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index          Word\n",
      "0       0           and\n",
      "1       1  applications\n",
      "2       2           are\n",
      "3       3      exciting\n",
      "4       4           fun\n",
      "5       5            is\n",
      "6       6      language\n",
      "7       7      learning\n",
      "8       8       machine\n",
      "9       9        modern\n",
      "10     10       natural\n",
      "11     11           nlp\n",
      "12     12        powers\n",
      "13     13    processing\n",
      "14     14            we\n"
     ]
    }
   ],
   "source": [
    "inv_vocab = sorted([(index, word) for word, index in vocab.items()])\n",
    "vocab_df = pd.DataFrame(inv_vocab, columns=[\"Index\", \"Word\"])\n",
    "\n",
    "print(vocab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f61a576-5ddc-42f7-9ca6-537d4a36cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 1 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 1 1 0 0 1 0 0 1 1]\n",
      " [0 1 0 0 0 0 0 1 1 1 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(documents)\n",
    "print(count_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8caa533b-236c-49f2-8475-0d6cc241d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 2 1 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "word_counts = np.array(count_matrix.sum(axis=0)).flatten()\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d137f6-4b79-4808-8020-ac9fe4476d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef441428-c4e6-4dcd-a555-d1cceb4fded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]]\n",
      "[[0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]]\n",
      "[[0.40824829 0.40824829 0.40824829 0.40824829 0.40824829 0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc1 = \"She loves food with cheese.\"\n",
    "doc2 = \"Her favorite food is Italian.\"\n",
    "doc3 = \"She lives in the Italian state.\"\n",
    "\n",
    "X1 = TfidfVectorizer().fit_transform([doc1])\n",
    "X2 = TfidfVectorizer().fit_transform([doc2])\n",
    "X3 = TfidfVectorizer().fit_transform([doc3])\n",
    "print(X1.toarray())\n",
    "print(X2.toarray())\n",
    "print(X3.toarray())\n",
    "summary=Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341decc7-640d-49b0-b678-4098c444627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49047908 0.         0.37302199 0.         0.         0.\n",
      "  0.         0.         0.49047908 0.37302199 0.         0.\n",
      "  0.49047908]\n",
      " [0.         0.49047908 0.37302199 0.49047908 0.         0.49047908\n",
      "  0.37302199 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.44036207 0.\n",
      "  0.3349067  0.44036207 0.         0.3349067  0.44036207 0.44036207\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = TfidfVectorizer().fit_transform([doc1,doc2,doc3])\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7704f24-cc8c-4567-b1e2-75aa7dd334ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample statements\n",
    "doc2 = [\n",
    "    \"NLP is fun and exciting\",\n",
    "    \"We are learning natural language processing\",\n",
    "    \"Machine learning powers modern NLP applications\",\n",
    "    \"Natural language processing is a fascinating field\",\n",
    "    \"Deep learning improves NLP performance\",\n",
    "    \"We enjoy exploring text mining techniques\",\n",
    "    \"AI is transforming language understanding\"\n",
    "]\n",
    "\n",
    "# Step 1: Create TF-IDF Vectorizer and transform the documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557ffc8-395a-4770-bfdd-bdf530913d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Step 3: Convert to DataFrame for better display\n",
    "cosine_df = pd.DataFrame(cosine_sim, index=[f\"Doc{i+1}\" for i in range(len(documents))],\n",
    "                         columns=[f\"Doc{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "# Display TF-IDF scores (optional)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(),\n",
    "                        index=[f\"Doc{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_df.round(3))\n",
    "\n",
    "print(\"\\nCosine Similarity Matrix:\")\n",
    "print(cosine_df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1311378-7627-4532-aa22-863ece90963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Create CountVectorizer and transform the documents\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 2: Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "\n",
    "# Step 3: Convert to DataFrame for display\n",
    "cosine_df = pd.DataFrame(cosine_sim, index=[f\"Doc{i+1}\" for i in range(len(documents))],\n",
    "                         columns=[f\"Doc{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "# Display Term Frequency matrix\n",
    "count_df = pd.DataFrame(count_matrix.toarray(), columns=vectorizer.get_feature_names_out(),\n",
    "                        index=[f\"Doc{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "print(\"\\nTerm Frequency Matrix:\")\n",
    "print(count_df)\n",
    "\n",
    "print(\"\\nCosine Similarity Matrix:\")\n",
    "print(cosine_df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "815913f3-cf26-4d1e-bf4e-8ec83e4220a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Cosine Similarity Matrix:\n",
      "       Doc1   Doc2   Doc3   Doc4   Doc5   Doc6   Doc7\n",
      "Doc1  1.000  0.000  0.112  0.120  0.126  0.000  0.126\n",
      "Doc2  0.000  1.000  0.111  0.445  0.125  0.143  0.125\n",
      "Doc3  0.112  0.111  1.000  0.000  0.225  0.000  0.000\n",
      "Doc4  0.120  0.445  0.000  1.000  0.000  0.000  0.240\n",
      "Doc5  0.126  0.125  0.225  0.000  1.000  0.000  0.000\n",
      "Doc6  0.000  0.143  0.000  0.000  0.000  1.000  0.000\n",
      "Doc7  0.126  0.125  0.000  0.240  0.000  0.000  1.000\n",
      "\n",
      "CountVectorizer Cosine Similarity Matrix:\n",
      "       Doc1   Doc2   Doc3   Doc4   Doc5   Doc6   Doc7\n",
      "Doc1  1.000  0.000  0.183  0.183  0.200  0.000  0.200\n",
      "Doc2  0.000  1.000  0.167  0.500  0.183  0.167  0.183\n",
      "Doc3  0.183  0.167  1.000  0.000  0.365  0.000  0.000\n",
      "Doc4  0.183  0.500  0.000  1.000  0.000  0.000  0.365\n",
      "Doc5  0.200  0.183  0.365  0.000  1.000  0.000  0.000\n",
      "Doc6  0.000  0.167  0.000  0.000  0.000  1.000  0.000\n",
      "Doc7  0.200  0.183  0.000  0.365  0.000  0.000  1.000\n",
      "\n",
      "TF-IDF Feature Names: ['ai' 'and' 'applications' 'are' 'deep' 'enjoy' 'exciting' 'exploring'\n",
      " 'fascinating' 'field'] ...\n",
      "CountVectorizer Feature Names: ['ai' 'and' 'applications' 'are' 'deep' 'enjoy' 'exciting' 'exploring'\n",
      " 'fascinating' 'field'] ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"NLP is fun and exciting\",\n",
    "    \"We are learning natural language processing\",\n",
    "    \"Machine learning powers modern NLP applications\",\n",
    "    \"Natural language processing is a fascinating field\",\n",
    "    \"Deep learning improves NLP performance\",\n",
    "    \"We enjoy exploring text mining techniques\",\n",
    "    \"AI is transforming language understanding\"\n",
    "]\n",
    "\n",
    "# ---------- TF-IDF ----------\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_cosine = cosine_similarity(tfidf_matrix)\n",
    "tfidf_df = pd.DataFrame(tfidf_cosine, \n",
    "                        index=[f\"Doc{i+1}\" for i in range(len(documents))],\n",
    "                        columns=[f\"Doc{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "# ---------- CountVectorizer ----------\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(documents)\n",
    "count_cosine = cosine_similarity(count_matrix)\n",
    "count_df = pd.DataFrame(count_cosine, \n",
    "                        index=[f\"Doc{i+1}\" for i in range(len(documents))],\n",
    "                        columns=[f\"Doc{i+1}\" for i in range(len(documents))])\n",
    "\n",
    "# ---------- Display ----------\n",
    "print(\"\\nTF-IDF Cosine Similarity Matrix:\")\n",
    "print(tfidf_df.round(3))\n",
    "\n",
    "print(\"\\nCountVectorizer Cosine Similarity Matrix:\")\n",
    "print(count_df.round(3))\n",
    "\n",
    "# Optional: Show top 10 terms from each method\n",
    "print(\"\\nTF-IDF Feature Names:\", tfidf_vectorizer.get_feature_names_out()[:10], \"...\")\n",
    "print(\"CountVectorizer Feature Names:\", count_vectorizer.get_feature_names_out()[:10], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ed6ee-65bf-49fb-bb52-6c295eeb831c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
